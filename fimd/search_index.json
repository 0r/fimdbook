[
["index.html", "", " "],
["foreword.html", "Foreword", " Foreword I’m delighted to see this new book on multiple imputation by Stef van Buuren for several reasons. First, to me at least, having another book devoted to multiple imputation marks the maturing of the topic after an admittedly somewhat shaky initiation. Stef is certainly correct when he states in Section 2.1.2: “The idea to create multiple versions must have seemed outrageous at that time (late 1970’s). Drawing imputations from a distribution, instead of estimating the ‘best’ value, was a severe breach with everything that had been done before.” I remember how this idea of multiple imputation was even ridiculed by some more traditional statisticians, sometimes for just being “silly” and sometimes for being hopelessly inefficient with respect to storage demands and outrageously expensive with respect to computational requirements. Some others of us foresaw what was happening to both (a) computational storage (I just acquired a 64 GB flash drive the size of a small finger for under $60, whereas only a couple of decades ago I paid over $2500 for a 120 KB hard drive larger than a shoebox weighing about 10 kilos), and (b) computational speed and flexibility. To develop statistical methods for the future while being bound by computational limitations of the past was clearly inapposite. Multiple imputation’s early survival was clearly due to the insight of a younger generation of statisticians, including many colleagues and former students, who realized future possibilities. A second reason for my delight at the publication of this book is more personal and concerns the maturing of the author, Stef van Buuren. As he mentions, we first met through Jan van Rijckevorsel at TNO. Stef was a young and enthusiastic researcher there, who knew little about the kind of statistics that I felt was essential for making progress on the topic of dealing with missing data. But consider the progress over the decades starting with his earlier work on MICE! Stef has matured into an independent researcher making important and original contributions to the continued development of multiple imputation. This book represents a ‘no nonsense’ straightforward approach to the application of multiple imputation. I particularly like Stef’s use of graphical displays, which are badly needed in practice to supplement the more theoretical discussions of the general validity of multiple imputation methods. As I have said elsewhere, and as implied by much of what is written by Stef, “It’s not that multiple imputation is so good; it’s really that other methods for addressing missing data are so bad.” It’s great to have Stef’s book on multiple imputation, and I look forward to seeing more editions as this rapidly developing methodology continues to become even more effective at handling missing data problems in practice. Finally, I would like to say that this book reinforces the pride of an academic father who has watched one of his children grow and develop. This book is a step in the growing list of contributions that Stef has made, and, I am confident, will continue to make, in methodology, computational approaches and application of multiple imputation. — Donald B. Rubin I am very pleased for the opportunity to add this short addendum to my preface to the first edition of Stef’s wonderfully readable book on multiple imputation. Over the past few years, I’ve recommended that many check out Stef’s first edition for excellent advice to practitioners of multiple imputation. The increased appreciation and use of multiple imputation between these two editions reflects, not only the growing maturity of computational statistics, but also the growing acceptance of multiple imputation as essentially being “the only game in town” for dealing generally with the problem of missing data, especially because it leads so naturally to visual displays of sensitivity of conclusions to differing assumptions about the reasons for the missing data. I am enthusiastic about the growing role of sensitivity analysis using visual displays, always prominent in Stef’s contributions, but also now in other places, such as Liublinska and Rubin (2014) — some of us can be slow learners! — Donald B. Rubin, May 2018 "],
["preface-to-second-edition.html", "Preface to second edition", " Preface to second edition Welcome to the second edition of Flexible Imputation of Missing Data, a book that can help you to solve missing data problems using mice. I am tremendously grateful for the success of the first edition. The mice community has been steadily growing over the last years, and the mice package is now downloaded from CRAN at a rate of about 750 downloads per day. My hope is that this book will sharpen your intuition on how to think about missing data, and provide you the tools to apply your ideas in practice. Since the first edition was published in 2012, multiple imputation of missing data has become one of the great academic industries. Many analysts now employ multiple imputation on a regular basis as a generic solution to the omnipresent missing-data problem, and a substantial group of practitioners are doing the calculations in mice. This book aspires to combine a state-of-the-art overview of the field with a set of how-to instructions for practical data analysis. Some sections of the first edition are still perfectly fine, but many others appear outdated. And of course, some of the newer developments are missing from the first edition. The second edition brings the text up-to-date. So what’s new? Multiple imputation of multilevel data has been a hot spot of statistical research. Multilevel data can arise from nested data collection designs, but also emerge when data are combined from multiple sources. Imputers and analysts now have a bewildering array of options. The three pages in the first edition have expanded into a full-blown new chapter on multilevel imputation. This chapter translates the current insights among the leading developers into practical advice for end users. Another hot spot in statistics and data science is the creation of personalized estimates. Causal inference by multiple imputation of the potential outcomes is an innovative approach that attempts to answer “what if” questions on the level of the individual. This edition contains a short new chapter on individual causal effects that demonstrates how multiple imputation is applied to obtain well-grounded personalized estimates. Data science has continued to grow at a phenomenal pace. The R language is now the dominant software for developing new statistical techniques. RStudio has successfully introduced the open tidyverse ecosystem for data acquisition, organization, analysis and visualization. This edition targets this growing audience of data scientists by including new sections on parallel computation and MICE workflows using pipes within the tidyverse ecosystem. New algorithms for creating imputations have appeared, in particular methodology based on predictive mean matching, for imputing binary and ordered variables, for interactions using classification and regression trees, and many types of machine learning methods. Chapters 3 and 4 incorporate these developments. Important theoretical advances have been made on the convergence, compatibility, misspecification and stability of the simulation algorithms underlying MICE. Chapter 4 in this edition highlights these developments. In parallel to the book, I worked on a significant update of the software: mice 3.0. The main MICE algorithm now iterates over blocks of variables instead of individual columns, so we may now easily combine univariate and multivariate imputation methods. In addition, it is now possible to specify exactly which cells in the data should be imputed. There are new functions for multivariate tests, the support for native formula’s has improved, and, thanks to the broom package, parameter pooling is now available for a much wider selection of complete-data models. The calculations use better numerical algorithms for low-level imputation functions. I have tried hard to remain code-compatible with previous versions of mice. Existing code should run properly, but do not expect exact replication of the results. All code used in this book was tested with mice 3.0. The previous edition had two colors, and some of the plots did not work as well as I had intended. I am very glad that this edition is in full color, so that the differences between the blue and red points stand out clearly and provide a unifying look to the book. There is also syntax coloring of the R code, which makes it very easy to distinguish the various language elements. All data are incomplete, and so are all books. I had the luxury that I could devote my time during the period December 2017-March 2018 to this revision. A block of four months may seem like a formidable amount of time, but in retrospect it passed very quickly. While some topics I had planned have remained in the conceptual stage, overall I think that this edition covers the relevant developments in the field. New statistical techniques will only be applied if there is high-quality and user-friendly software available. I would like to thank the following people for their contribution to the mice package over the years: Karin Groothuis-Oudshoorn, Gerko Vink, Lisa Doove, Shahab Jolani, Roel de Jong, Rianne Schouten, Florian Meinfelder, Philipp Gaffert, Alexander Robitzsch and Bernie Gray. There is a growing ecosystem of related R packages that extend the functionality of mice in some way. Currently, these include miceadds, mitml, micemd, countimp, CALIBERrfimpute, miceExt and ImputeRobust. There is also a Python version in the works, which could result in an enormous expansion of the user base. I thank the authors of these packages for the time and effort they have put into creating these programs: Alexander Robitzsch, Simon Grund, Thorsten Henke, Oliver Lüdtke, Vincent Audigier, Matthieu Resche-Rigon, Kristian Kleinke, Jost Reinecke, Anoop Shah, Tobias Schumacher, Philipp Gaffert, Daniel Salfran, Martin Spiess, Sergey Feldman and Rianne Schouten. I wish to thank Rob Calver, Statistics Editor at Chapman &amp; Hall/CRC for his encouragement during both the first and second edition. Lara Spieker, Suzanne Lassandro and Shashi Kumar have been very helpful in meeting the ambitious production schedule. I thank Daan Kloet of TNO for his support for the idea of a mini-sabbatical, and his assistence in realizing the idea within TNO. I also wish to thank Peter van der Heijden of the University of Utrecht for his support over the years. Several people read and commented on parts of the manuscript. I thank Gerko Vink, Shahab Jolani, Iris Eekhout, Simon Grund, Tom Snijders and Joop Hox for their insightful and useful feedback. This has helped me a lot to understand the details much clearer, allowing me to improve my fumbled writings. Last but not least, I thank my wife Eveline for her patience in living with an individual who can be so preoccupied with something else. — Stef van Buuren, May 2, 2018 "],
["preface-to-first-edition.html", "Preface to first edition", " Preface to first edition We are surrounded by missing data. Problems created by missing data in statistical analysis have long been swept under the carpet. These times are now slowly coming to an end. The array of techniques for dealing with missing data has expanded considerably during the last decades. This book is about one such method: multiple imputation. Multiple imputation is one of the great ideas in statistical science. The technique is simple, elegant and powerful. It is simple because it fills the holes in the data with plausible values. It is elegant because the uncertainty about the unknown data is coded in the data itself. And it is powerful because it can solve “other” problems that are actually missing data problems in disguise. Over the last 20 years, I have applied multiple imputation in a wide variety of projects. I believe the time is ripe for multiple imputation to enter mainstream statistics. Computers and software are now potent enough to do the required calculations with little effort. What is still missing is a book that explains the basic ideas and that shows how these ideas can be put into practice. My hope is that this book can fill this gap. The text assumes familiarity with basic statistical concepts and multivariate methods. The book is intended for two audiences: (bio)statisticians, epidemiologists and methodologists in the social and health sciences; substantive researchers who do not call themselves statisticians, but who possess the necessary skills to understand the principles and to follow the recipes. In writing this text, I have tried to avoid mathematical and technical details as much as possible. Formulas are accompanied by a verbal statement that explains the formula in layperson terms. I hope that readers less concerned with the theoretical underpinnings will be able to pick up the general idea. The more technical material is marked by a club sign \\(^\\spadesuit\\), and can be skipped on first reading. I used various parts of the book to teach a graduate course on imputation techniques at the University of Utrecht. The basics are in Chapters 1–4. Lecturing this material takes about 10 hours. The lectures were interspersed with sessions in which the students worked out the exercises from the book. This book owes much to the ideas of Donald Rubin, the originator of multiple imputation. I had the privilege of being able to talk, meet and work with him on many occasions. His clear vision and deceptively simple ideas have been a tremendous source of inspiration. I am also indebted to Jan van Rijckevorsel for bringing me into contact with Donald Rubin, and for establishing the scientific climate at TNO in which our work on missing data techniques could prosper. Many people have helped realize this project. I thank Nico van Meeteren and Michael Holewijn of TNO for their trust and support. I thank Peter van der Heijden of Utrecht University for his support. I thank Rob Calver and the staff at Chapman &amp; Hall/CRC for their help and advice. Many colleagues have commented on part or all of the manuscript: Hendriek Boshuizen, Elise Dusseldorp, Karin Groothuis-Oudshoorn, Michael Hermanussen, Martijn Heymans, Nicholas Horton, Shahab Jolani, Gerko Vink, Ian White and the research master students of the Spring 2011 class. Their comments have been very valuable for detecting and eliminating quite a few glitches. I happily take the blame for the remaining errors and vagaries. The major part of the manuscript was written during a six-month sabbatical leave. I spent four months in Krukö, Sweden, a small village of just eight houses. I thank Frank van den Nieuwenhuijzen and Ynske de Koning for making their wonderful green house available to me. It was the perfect tranquil environment that, apart from snowplowing, provided a minimum of distractions. I also spent two months at the residence of Michael Hermanussen and Beate Lohse-Hermanussen in Altenhof, Germany. I thank them for their hospitality, creativity and wit. It was a wonderful time. Finally, I thank my family, in particular my beloved wife Eveline, for their warm and ongoing support, and for allowing me to devote time, often nights and weekends, to work on this book. Eveline liked to tease me by telling people that I was writing “a book that no one understands.” I fear that her statement is accurate, at least for 99% of the people. My hope is that you, my dear reader, will belong to the remaining 1%. "],
["about-the-author.html", "About the author", " About the author Stef van Buuren is a statistician at the Netherlands Organization for Applied Scientific Research TNO in Leiden, and professor of Statistical Analysis of Incomplete Data at Utrecht University. He is the originator of the MICE algorithm for multiple imputation of multivariate data, and co-developed the mice package in R. More information can be found at stefvanbuuren.name. Voor Eveline, Guus, Otto en Maaike "],
["symbol-description.html", "Symbol Description", " Symbol Description Symbol Description Section \\(Y\\) \\(n \\times p\\) matrix of partially observed sample data ?? \\(R\\) \\(n \\times p\\) matrix, 0-1 response indicator of \\(Y\\) ?? \\(X\\) \\(n \\times q\\) matrix of predictors, used for various purposes ?? \\(Y_\\mathrm{obs}\\) observed sample data, values of \\(Y\\) with \\(R=1\\) ?? \\(Y_\\mathrm{mis}\\) unobserved sample data, values of \\(Y\\) with \\(R=0\\) ?? \\(n\\) sample size ?? \\(m\\) number of multiple imputations ?? \\(\\psi\\) parameters of the missing data model that relates \\(Y\\) to \\(R\\) ?? \\(\\theta\\) parameters of the scientifically interesting model for the full data \\(Y\\) ?? \\(Q\\) \\(k \\times 1\\) vector with \\(k\\) scientific estimands ?? \\(\\hat Q\\) \\(k \\times 1\\) vector, estimate of \\(Q\\) calculated from a hypothetically complete sample \\(U\\) \\(k \\times k\\) matrix, within-imputation variance due to sampling ?? \\(\\ell\\) imputation number, where \\(\\ell = 1, \\dots, m\\) ?? \\(Y_\\ell\\) \\(\\ell^\\mathrm{th}\\) imputed dataset, where \\(\\ell = 1, \\dots, m\\) ?? \\(\\bar Q\\) \\(k \\times 1\\) vector, estimate of \\(Q\\) calculated from the incompletely observed sample ?? \\(\\bar U\\) \\(k \\times k\\), estimate of \\(U\\) from the incomplete data ?? \\(B\\) \\(k \\times k\\), between-imputation variance due to nonresponse ?? \\(T\\) total variance of \\((Q-\\bar Q)\\), \\(k \\times k\\) matrix ?? \\(\\lambda\\) proportion of the variance attributable to the missing data for a scalar parameter ?? \\(\\gamma\\) fraction of information missing due to nonresponse ?? \\(r\\) relative increase of variance due to nonresponse for a scalar parameter ?? \\(\\bar\\lambda\\) \\(\\lambda\\) for multivariate \\(Q\\) ?? \\(\\bar r\\) \\(r\\) for multivariate \\(Q\\) ?? \\(\\nu_\\mathrm{old}\\) old degrees of freedom ?? \\(\\nu\\) adjusted degrees of freedom ?? \\(y\\) univariate \\(Y\\) ?? \\(y_\\mathrm{obs}\\) vector with \\(n_1\\) observed data values in \\(y\\) ?? \\(y_\\mathrm{mis}\\) vector with \\(n_0\\) missing data values in \\(y\\) ?? \\(\\dot y\\) vector \\(n_0\\) imputed values in \\(y\\) ?? \\(X_\\mathrm{obs}\\) subset of \\(n_1\\) rows of \\(X\\) for which \\(y\\) is observed ?? \\(X_\\mathrm{mis}\\) subset of \\(n_0\\) rows of \\(X\\) for which \\(y\\) is missing ?? \\(\\hat\\beta\\) estimate of regression weight \\(\\beta\\) ?? \\(\\dot\\beta\\) simulated regression weight for \\(\\beta\\) ?? \\(\\hat\\sigma^2\\) estimate of residual variance \\(\\sigma^2\\) ?? \\(\\dot\\sigma^2\\) simulated residual variance for \\(\\sigma^2\\) ?? \\(\\kappa\\) ridge parameter ?? \\(\\eta\\) distance parameter in predictive mean matching ?? \\(\\hat y_i\\) vector of \\(n_1\\) predicted values given \\(X_\\mathrm{obs}\\) ?? \\(\\hat y_j\\) vector of \\(n_0\\) predicted values given \\(X_\\mathrm{mis}\\) ?? \\(\\delta\\) shift parameter in nonignorable models ?? \\(Y_j\\) \\(j^\\mathrm{th}\\) column of \\(Y\\) ?? \\(Y_{-j}\\) all columns of \\(Y\\) except \\(Y_j\\) ?? \\(I_{jk}\\) proportion of usable cases for imputing \\(Y_j\\) from \\(Y_k\\) ?? \\(O_{jk}\\) proportion of observed cases in \\(Y_j\\) to impute \\(Y_k\\) ?? \\(I_j\\) influx statistic to impute \\(Y_j\\) from \\(Y_{-j}\\) ?? \\(O_j\\) outflux statistic to impute \\(Y_{-j}\\) from \\(Y_j\\) ?? \\(\\phi\\) parameters of the imputation model that models the distribution of \\(Y\\) ?? \\(M\\) number of iterations ?? \\(D_1\\) test statistic of Wald test ?? \\(r_1\\) \\(r\\) for Wald test ?? \\(\\nu_1\\) \\(\\nu\\) for Wald test ?? \\(D_2\\) test statistic for \\(\\chi^2\\)-test ?? \\(r_2\\) \\(r\\) for \\(\\chi^2\\)-test ?? \\(\\nu_2\\) \\(\\nu\\) for \\(\\chi^2\\)-test ?? \\(D_3\\) test statistic for likelihood ratio test ?? \\(r_3\\) \\(r\\) for likelihood ratio test ?? \\(\\nu_3\\) \\(\\nu\\) for likelihood ratio test ?? \\(C\\) number of classes ?? \\(c\\) class index, \\(c=1,\\dots,C\\) ?? \\(y_c\\) outcome vector for cluster \\(c\\) ?? \\(X_c\\) design matrix, fixed effects ?? \\(Z_c\\) design matrix, random effects ?? \\(\\Omega\\) covariance matrix, random effects ?? \\(Y_i(1)\\) outcome of unit \\(i\\) under treatment ?? \\(Y_i(0)\\) outcome of unit \\(i\\) under control ?? \\(\\tau_i\\) individual causal effect ?? \\(\\tau\\) average causal effect ?? \\(\\dot\\tau_{i\\ell}\\) simulated \\(\\tau_i\\) in \\(\\ell^\\mathrm{th}\\) imputed data set ?? \\(\\hat\\tau_{i}\\) estimate of \\(\\tau_i\\) ?? \\(\\hat\\sigma_i^2\\) variance estimate of \\(\\hat\\tau_{i}\\) ?? \\(\\dot\\tau_{\\ell}\\) simulated within-replication average causal effect ?? \\(\\dot\\sigma_{\\ell}^2\\) variance of \\(\\dot\\tau_{\\ell}\\) ?? "],
["ch-introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction We should be suspicious of any dataset (large or small) which appears perfect. — David J. Hand "],
["sec-problem.html", "1.1 The problem of missing data", " 1.1 The problem of missing data 1.1.1 Current practice The mean of the numbers 1, 2 and 4 can be calculated in R as y &lt;- c(1, 2, 4) mean(y) [1] 2.33 where y is a vector containing three numbers, and where mean(y) is the R expression that returns their mean. Now suppose that the last number is missing. R indicates this by the symbol NA, which stands for “not available”: y &lt;- c(1, 2, NA) mean(y) [1] NA The mean is now undefined, and R informs us about this outcome by setting the mean to NA. It is possible to add an extra argument na.rm = TRUE to the function call. This removes any missing data before calculating the mean: mean(y, na.rm = TRUE) [1] 1.5 This makes it possible to calculate a result, but of course the set of observations on which the calculations are based has changed. This may cause problems in statistical inference and interpretation. It gets worse with multivariate analysis. For example, let us try to predict daily ozone concentration (ppb) from wind speed (mph) using the built-in airquality dataset. We fit a linear regression model by calling the lm() function to predict daily ozone levels, as follows: ## fit &lt;- lm(Ozone ~ Wind, data = airquality) ## Error in na.fail.default: missing values in object} Many R users have seen this message. The code cannot continue because there are missing values. One way to circumvent the problem is to omit any incomplete records by specifying the na.action = na.omit argument to lm(). The regression weights can now be obtained as fit &lt;- lm(Ozone ~ Wind, data = airquality, na.action = na.omit) This works. For example, we may produce diagnostic plots by plot(fit) to study the quality of the model. In practice, it is cumbersome to supply the na.action() function each time. We can change the setting in options as options(na.action = na.omit) which eliminates the error message once and for all. Users of other software packages like SPSS, SAS and Stata enjoy the “luxury” that this deletion option has already been set for them, so the calculations can progress silently. Next, we wish to plot the predicted ozone levels against the observed data, so we use predict() to calculate the predicted values, and add these to the data to prepare for plotting. ## airquality2 &lt;- cbind(airquality, predict(fit)) ## Error: arguments imply differing number of rows: 153, 116 Argg… that doesn’t work either. The error message tells us that the two datasets have a different number of rows. The airquality data has 153 rows, whereas there are only 116 predicted values. The problem, of course, is that there are missing data. The lm() function dropped any incomplete rows in the data. We find the indices of the first six cases by head(na.action(fit)) 5 10 25 26 27 32 5 10 25 26 27 32 The total number of deleted cases is found as naprint(na.action(fit)) [1] &quot;37 observations deleted due to missingness&quot; The number of missing values per variable in the data is colSums(is.na(airquality)) Ozone Solar.R Wind Temp Month Day 37 7 0 0 0 0 so in our regression model, all 37 deleted cases have missing ozone scores. Removing the incomplete cases prior to analysis is known as listwise deletion or complete-case analysis. In R, there are two related functions for the subset of complete cases, na.omit() and complete.cases(). Figure 1.1 plots the predicted against the observed values. Here we adopt the Abayomi convention for the colors (Abayomi, Gelman, and Levy 2008): Blue refers to the observed part of the data, red to the synthetic part of the data (also called the imputed values or imputations), and black to the combined data (also called the imputed data or completed data). The printed version of the first edition of this book used gray instead of blue. The blue points on the left are all from the complete cases, whereas the figure on the right plots the points for the incomplete cases (in red). Since there are no measured ozone levels in that part of the data, the possible values are indicated by 37 horizontal lines. airquality2 &lt;- cbind(na.omit(airquality[, c(&quot;Ozone&quot;, &quot;Wind&quot;)]), predicted = predict(fit)) Figure 1.1: Predicted versus measured ozone levels for the observed (left, blue) and missing values (right, red). Listwise deletion allows the calculations to proceed, but it may introduce additional complexities in interpretation. Let’s try to find a better predictive model by including solar radiation (Solar.R) into the model as fit2 &lt;- lm(Ozone ~ Wind + Solar.R, data = airquality) naprint(na.action(fit2)) [1] &quot;42 observations deleted due to missingness&quot; Observe that the number of deleted days increased is now 42 since some rows had no value for Solar.R. Thus, changing the model altered the sample. There are methodological and statistical issues associated with this procedure. Some questions that come to mind are: Can we compare the regression coefficients from both models? Should we attribute differences in the coefficients to changes in the model or to changes in the subsample? Do the estimated coefficients generalize to the study population? Do we have enough cases to detect the effect of interest? Are we making the best use of the costly collected data? Getting the software to run is one thing, but this alone does not address the challenges posed by the missing data. Unless the analyst, or the software vendor, provides some way to work around the missing values, the analysis cannot continue because calculations on missing values are not possible. There are many approaches to circumvent this problem. Each of these affects the end result in a different way. Some solutions are clearly better than others, and there is no solution that will always work. This chapter reviews the major approaches, and discusses their advantages and limitations. 1.1.2 Changing perspective on missing data The standard approach to missing data is to delete them. It is illustrative to search for missing values in published data. Hand et al. (1994) published a highly useful collection of small datasets across the statistical literature. The collection covers an impressive variety of topics. Only 13 out of the 510 datasets in the collection actually had a code for the missing data. In many cases, the missing data problem has probably been “solved” in some way, usually without telling us how many missing values there were originally. It is impossible to track down the original data for most datasets in Hand’s book. However, we can easily do this for dataset number 357, a list of scores of 34 athletes in 10 sport events at the 1988 Olympic decathlon in Seoul. The table itself is complete, but a quick search on the Internet revealed that initially 39 instead of 34 athletes participated. Five of them did not finish for various reasons, including the dramatic disqualification of the German favorite Jürgen Hingsen because of three false starts in the 100-meter sprint. It is probably fair to assume that deletion occurred silently in many of the other datasets. The inclination to delete the missing data is understandable. Apart from the technical difficulties imposed by the missing data, the occurrence of missing data has long been considered a sign of sloppy research. It is all too easy for a referee to write: This study is weak because of the large amount of missing data. Publication chances are likely to improve if there is no hint of missingness. Orchard and Woodbury (1972, 697) remarked: Obviously the best way to treat missing data is not to have them. Though there is a lot of truth in this statement, Orchard and Woodbury realized the impossibility of attaining this ideal in practice. The prevailing scientific practice is to downplay the missing data. Reviews on reporting practices are available in various fields: clinical trials (Wood, White, and Thompson 2004; Powney et al. 2014; Díaz-Ordaz et al. 2014; Akl et al. 2015), cancer research (Burton and Altman 2004), educational research (Peugh and Enders 2004), epidemiology (Klebanoff and Cole 2008; Karahalios et al. 2012), developmental psychology (Jeliĉić, Phelps, and Lerner 2009), general medicine (Mackinnon 2010), developmental pediatrics (Aylward, Anderson, and Nelson 2010), and otorhinolaryngology, head and neck surgery (Netten et al. 2017). The picture that emerges from these studies is quite consistent: The presence of missing data is often not explicitly stated in the text; Default methods, such as listwise deletion are used without mentioning them; Different tables are based on different sample sizes; Model-based missing data methods, such as direct likelihood, full information maximum likelihood and multiple imputation, are notably underutilized. Helpful resources include the STROBE (Vandenbroucke et al. 2007) and CONSORT checklists and flow charts (Schulz, Altman, and Moher 2010). Gomes et al. (2016) showed cases where the subset of full patient-reported outcomes is a selective, leading to misleading results. Palmer et al. (2018) suggested a classification scheme for the reasons of nonresponse in patient-reported outcomes. Missing data are there, whether we like it or not. In the social sciences, it is nearly inevitable that some respondents will refuse to participate or to answer certain questions. In medical studies, attrition of patients is very common. The theory, methodology and software for handling incomplete data problems have been vastly expanded and refined over the last decades. The major statistical analysis packages now have facilities for performing the appropriate analyses. This book aims to contribute to a better understanding of the issues involved, and provides a methodology for dealing with incomplete data problems in practice. "],
["sec-MCAR.html", "1.2 Concepts of MCAR, MAR and MNAR", " 1.2 Concepts of MCAR, MAR and MNAR Before we review a number of simple fixes for the missing data in Section 1.3 let us take a short look at the terms MCAR, MAR and MNAR. A more detailed definition of these concepts will be given later in Section ??. Rubin (1976) classified missing data problems into three categories. In his theory every data point has some likelihood of being missing. The process that governs these probabilities is called the missing data mechanism or response mechanism. The model for the process is called the missing data model or response model. If the probability of being missing is the same for all cases, then the data are said to be missing completely at random (MCAR). This effectively implies that causes of the missing data are unrelated to the data. We may consequently ignore many of the complexities that arise because data are missing, apart from the obvious loss of information. An example of MCAR is a weighing scale that ran out of batteries. Some of the data will be missing simply because of bad luck. Another example is when we take a random sample of a population, where each member has the same chance of being included in the sample. The (unobserved) data of members in the population that were not included in the sample are MCAR. While convenient, MCAR is often unrealistic for the data at hand. If the probability of being missing is the same only within groups defined by the observed data, then the data are missing at random (MAR). MAR is a much broader class than MCAR. For example, when placed on a soft surface, a weighing scale may produce more missing values than when placed on a hard surface. Such data are thus not MCAR. If, however, we know surface type and if we can assume MCAR within the type of surface, then the data are MAR. Another example of MAR is when we take a sample from a population, where the probability to be included depends on some known property. MAR is more general and more realistic than MCAR. Modern missing data methods generally start from the MAR assumption. If neither MCAR nor MAR holds, then we speak of missing not at random (MNAR). In the literature one can also find the term NMAR (not missing at random) for the same concept. MNAR means that the probability of being missing varies for reasons that are unknown to us. For example, the weighing scale mechanism may wear out over time, producing more missing data as time progresses, but we may fail to note this. If the heavier objects are measured later in time, then we obtain a distribution of the measurements that will be distorted. MNAR includes the possibility that the scale produces more missing values for the heavier objects (as above), a situation that might be difficult to recognize and handle. An example of MNAR in public opinion research occurs if those with weaker opinions respond less often. MNAR is the most complex case. Strategies to handle MNAR are to find more data about the causes for the missingness, or to perform what-if analyses to see how sensitive the results are under various scenarios. Rubin’s distinction is important for understanding why some methods will work, and others not. His theory lays down the conditions under which a missing data method can provide valid statistical inferences. Most simple fixes only work under the restrictive and often unrealistic MCAR assumption. If MCAR is implausible, such methods can provide biased estimates. "],
["sec-simplesolutions.html", "1.3 Ad-hoc solutions", " 1.3 Ad-hoc solutions 1.3.1 Listwise deletion Complete-case analysis (listwise deletion) is the default way of handling incomplete data in many statistical packages, including SPSS, SAS and Stata. The function na.omit() does the same in S-PLUS and R. The procedure eliminates all cases with one or more missing values on the analysis variables. An important advantage of complete-case analysis is convenience. If the data are MCAR, listwise deletion produces unbiased estimates of means, variances and regression weights. Under MCAR, listwise deletion produces standard errors and significance levels that are correct for the reduced subset of data, but that are often larger relative to all available data. A disadvantage of listwise deletion is that it is potentially wasteful. It is not uncommon in real life applications that more than half of the original sample is lost, especially if the number of variables is large. G. King et al. (2001) estimated that the percentage of incomplete records in the political sciences exceeded 50% on average, with some studies having over 90% incomplete records. It will be clear that a smaller subsample could seriously degrade the ability to detect the effects of interest. If the data are not MCAR, listwise deletion can severely bias estimates of means, regression coefficients and correlations. Little and Rubin (2002, 41–44) showed that the bias in the estimated mean increases with the difference between means of the observed and missing cases, and with the proportion of the missing data. Schafer and Graham (2002) reported an elegant simulation study that demonstrates the bias of listwise deletion under MAR and MNAR. However, complete-case analysis is not always bad. The implications of the missing data are different depending on where they occur (outcomes or predictors), and the parameter and model form of the complete-data model. In the context of regression analysis, listwise deletion possesses some unique properties that make it attractive in particular settings. There are cases in which listwise deletion can provide better estimates than even the most sophisticated procedures. Since their discussion requires a bit more background than can be given here, we defer the treatment to Section ??. Listwise deletion can introduce inconsistencies in reporting. Since listwise deletion is automatically applied to the active set of variables, different analyses on the same data are often based on different subsamples. In principle, it is possible to produce one global subsample using all active variables. In practice, this is unattractive since the global subsample will always have fewer cases than each of the local subsamples, so it is common to create different subsets for different tables. It will be evident that this complicates their comparison and generalization to the study population. In some cases, listwise deletion can lead to nonsensical subsamples. For example, the rows in the airquality dataset used in Section 1.1.1 correspond to 154 consecutive days between May 1, 1973 and September 30, 1973. Deleting days affects the time basis. It would be much harder, if not impossible, to perform analyses that involve time, e.g., to identify weekly patterns or to fit autoregressive models that predict from previous days. The opinions on the merits of listwise deletion vary. Miettinen (1985, 231) described listwise deletion as …the only approach that assures that no bias is introduced under any circumstances… a bold statement, but incorrect. At the other end of the spectrum we find Enders (2010, 39): In most situations, the disadvantages of listwise deletion far outweigh its advantages. Schafer and Graham (2002, 156) cover the middle ground: If a missing data problem can be resolved by discarding only a small part of the sample, then the method can be quite effective. The leading authors in the field are, however, wary of providing advice about the percentage of missing cases below which it is still acceptable to do listwise deletion. Little and Rubin (2002) argue that it is difficult to formulate rules of thumb since the consequences of using listwise deletion depend on more than the missing data rate alone. Vach (1994, 113) expressed his dislike for simplistic rules as follows: It is often supposed that there exists something like a critical missing rate up to which missing values are not too dangerous. The belief in such a global missing rate is rather stupid. 1.3.2 Pairwise deletion Pairwise deletion, also known as available-case analysis, attempts to remedy the data loss problem of listwise deletion. The method calculates the means and (co)variances on all observed data. Thus, the mean of variable \\(X\\) is based on all cases with observed data on \\(X\\), the mean of variable \\(Y\\) uses all cases with observed \\(Y\\)-values, and so on. For the correlation and covariance, all data are taken on which both \\(X\\) and \\(Y\\) have non-missing scores. Subsequently, the matrix of summary statistics are fed into a program for regression analysis, factor analysis or other modeling procedures. SPSS, SAS and Stata contain many procedures with an option for pairwise deletion. In R we can calculate the means and correlations of the airquality data under pairwise deletion in R as: data &lt;- airquality[, c(&quot;Ozone&quot;, &quot;Solar.R&quot;, &quot;Wind&quot;)] mu &lt;- colMeans(data, na.rm = TRUE) cv &lt;- cov(data, use = &quot;pairwise&quot;) The standard lm() function does not take means and covariances as input, but the lavaan package (Rosseel 2012) provides this feature: library(lavaan) fit &lt;- lavaan(&quot;Ozone ~ 1 + Wind + Solar.R Ozone ~~ Ozone&quot;, sample.mean = mu, sample.cov = cv, sample.nobs = sum(complete.cases(data))) The method is simple, and appears to use all available information. Under MCAR, it produces consistent estimates of mean, correlations and covariances (Little and Rubin 2002, 55). The method has also some shortcomings. First, the estimates can be biased if the data are not MCAR. Further, the covariance and/or correlation matrix may not be positive definite, which is requirement for most multivariate procedures. Problems are generally more severe for highly correlated variables (Little 1992). It is not clear what sample size should be used for calculating standard errors. Taking the average sample size yields standard errors that are too small(Little 1992). Also, pairwise deletion requires numerical data that follow an approximate normal distribution, whereas in practice we often have variables of mixed types. The idea to use all available information is good, but the proper analysis of the pairwise matrix requires sophisticated optimization techniques and special formulas to calculate the standard errors (Van Praag, Dijkstra, and Van Velzen 1985; Marsh 1998), which somewhat defeats its utility. Pairwise deletion works best used if the data approximate a multivariate normal distribution, if the correlations between the variables are low, and if the assumption of MCAR is plausible. It is not recommended for other cases. 1.3.3 Mean imputation A quick fix for the missing data is to replace them by the mean. We may use the mode for categorical data. Suppose we want to impute the mean in Ozone and Solar.R of the airquality data. SPSS, SAS and Stata have pre-built functions that substitute the mean. This book uses the R package mice (Van Buuren and Groothuis-Oudshoorn 2011). This software is a contributed package that extends the functionality of R. Before mice can be used, it must be installed. An easy way to do this is to type: install.packages(&quot;mice&quot;) which searches the Comprehensive R Archive Network (CRAN), and installs the requested package on the local computer. After succesful installation, the mice package can be loaded by library(&quot;mice&quot;) Imputing the mean in each variable can now be done by imp &lt;- mice(airquality, method = &quot;mean&quot;, m = 1, maxit = 1) iter imp variable 1 1 Ozone Solar.R The argument method = mean specifies mean imputation, the argument m = 1 requests a single imputed dataset, and maxit = 1 sets the number of iterations to 1 (no iteration). The latter two options can be left to their defaults with essentially the same result. Figure 1.2: Mean imputation of Ozone. Blue indicates the observed data, red indicates the imputed values. Mean imputation distorts the distribution in several ways. Figure 1.2 displays the distribution of Ozone after imputation. In the figure on the left, the red bar at the mean stands out. Imputing the mean here actually creates a bimodal distribution. The standard deviation in the imputed data is equal to 28.7, much smaller than from the observed data alone, which is 33. The figure on the right-hand side shows that the relation between Ozone and Solar.R is distorted because of the imputations. The correlation drops from 0.35 in the blue points to 0.3 in the combined data. Mean imputation is a fast and simple fix for the missing data. However, it will underestimate the variance, disturb the relations between variables, bias almost any estimate other than the mean and bias the estimate of the mean when data are not MCAR. Mean imputation should perhaps only be used as a rapid fix when a handful of values are missing, and it should be avoided in general. 1.3.4 Regression imputation Regression imputation incorporates knowledge of other variables with the idea of producing smarter imputations. The first step involves building a model from the observed data. Predictions for the incomplete cases are then calculated under the fitted model, and serve as replacements for the missing data. Suppose that we predict Ozone by linear regression from Solar.R. fit &lt;- lm(Ozone ~ Solar.R, data = airquality) pred &lt;- predict(fit, newdata = ic(airquality)) Figure 1.3: Regression imputation: Imputing Ozone from the regression line. Another possibility for regression imputation uses mice: data &lt;- airquality[, c(&quot;Ozone&quot;, &quot;Solar.R&quot;)] imp &lt;- mice(data, method = &quot;norm.predict&quot;, seed = 1, m = 1, print = FALSE) xyplot(imp, Ozone ~ Solar.R) Figure 1.3 shows the result. The imputed values correspond to the most likely values under the model. However, the ensemble of imputed values vary less than the observed values. It may be that each of the individual points is the best under the model, but it is very unlikely that the real (but unobserved) values of Ozone would have had this distribution. Imputing predicted values also has an effect on the correlation. The red points have a correlation of 1 since they are located on a line. If the red and blue dots are combined, then the correlation increases from 0.35 to 0.39. Note that this upward bias grows with the percent missing ozone levels (here 24%). Regression imputation yields unbiased estimates of the means under MCAR, just like mean imputation, and of the regression weights of the imputation model if the explanatory variables are complete. Moreover, the regression weights are unbiased under MAR if the factors that influence the missingness are part of the regression model. In the example this corresponds to the situation where Solar.R would explain any differences in the probability that Ozone is missing. On the other hand, correlations are biased upwards, and the variability of the imputed data is systematically underestimated. The degree of underestimation depends on the explained variance and on the proportion of missing cases (Little and Rubin 2002, 64). Imputing predicted values can yield realistic imputations if the prediction is close to perfection. If so, the method reconstructs the missing parts from the available data. In essence, there was not really any information missing in the first place, it was only coded in a different form. Regression imputation, as well as its modern incarnations in machine learning is probably the most dangerous of all methods described here. We may be led to believe that we’re to do a good job by preserving the relations between the variables. In reality however, regression imputation artificially strengthens the relations in the data. Correlations are biased upwards. Variability is underestimated. Imputations are too good to be true. Regression imputation is a recipe for false positive and spurious relations. 1.3.5 Stochastic regression imputation Stochastic regression imputation is a refinement of regression imputation attempts to address correlation bias by adding noise to the predictions. The following code imputes Ozone from Solar.R by stochastic regression imputation. data &lt;- airquality[, c(&quot;Ozone&quot;, &quot;Solar.R&quot;)] imp &lt;- mice(data, method = &quot;norm.nob&quot;, m = 1, maxit = 1, seed = 1, print = FALSE) Figure 1.4: Stochastic regression imputation of Ozone. The method = norm.nob argument requests a plain, non-Bayesian, stochastic regression method. This method first estimates the intercept, slope and residual variance under the linear model, then calculates the predicted value for each missing value, and adds a random draw from the residual to the prediction. We will come back to the details in Section ??. The seed argument makes the solution reproducible. Figure 1.4 shows that the addition of noise to the predictions opens up the distribution of the imputed values, as intended. Note that some new complexities arise. There is one imputation with a negative value. Such values need not be due to the draws from the residual distribution, but can also be a consequence of the use of a linear model for non-negative data. In fact, Figure 1.1 shows several negative predicted values in the observed data. Since negative Ozone concentrations do not exist in the real world, we cannot consider negative values as plausible imputations. Note also that the high end of the distribution is not well covered. The observed data form a cone, i.e., the data are heteroscedastic, but the imputation model assumes equal dispersion around the regression line. The variability of Ozone increases up to the solar radiation level of 250 langleys, and decreases after that. Though it is unclear whether this is a genuine meteorological phenomenon, the imputation model does not account for this feature. Nevertheless, stochastic regression imputation represents a major conceptual advance. Some analysts may find it counterintuitive to “spoil” the best prediction by adding random noise, yet this is precisely what makes it suitable for imputation. A well-executed stochastic regression imputation preserves not only the regression weights, but also the correlation between variables (cf. Exercise 1.3). The main idea to draw from the residuals is very powerful, and forms the basis of more advanced imputation techniques. 1.3.6 LOCF and BOCF Last observation carried forward (LOCF) and baseline observation carried forward (BOCF) are ad-hoc imputation methods for longitudinal data. The idea is to take the previous observed value as a replacement for the missing data. When multiple values are missing in succession, the method searches for the last observed value. The function fill() from the tidyr package applies LOCF by filling in the last known value. This is useful in situations where values are recorded only as they change, as in time-to-event data. For example, we may use LOCF to fill in Ozone by airquality2 &lt;- tidyr::fill(airquality, Ozone) Figure 1.5: Imputation of Ozone by last observation carried forward (LOCF). Figure 1.5 plots the results of the first 80 days of the Ozone series. The stretches of red dots indicate the imputations, and are constant within the same batch of missing ozone levels. The real, unseen values are likely to vary within these batches, so applying LOCF here gives implausible imputations. LOCF is convenient because it generates a complete dataset. It can be applied with confidence in cases where we are certain what the missing values should be, for example, for administrative variables in longitudinal data. For outcomes, LOCF is dubious. The method has long been used in clinical trials. The U.S. Food and Drug Administration (FDA) has traditionally viewed LOCF as the preferred method of analysis, considering it conservative and less prone to selection than listwise deletion. However, Molenberghs and Kenward (2007, 47–50) show that the bias can operate in both directions, and that LOCF can yield biased estimates even under MCAR. LOCF needs to be followed by a proper statistical analysis method that distinguishes between the real and imputed data. This is typically not done however. Additional concerns about a reversal of the time direction are given in Kenward and Molenberghs (2009). The Panel on Handling Missing Data in Clinical Trials recommends that LOCF and BOCF should not be used as the primary approach for handling missing data unless the assumptions that underlie them are scientifically justified (National Research Council 2010, 77). 1.3.7 Indicator method Suppose that we want to fit a regression, but there are missing values in one of the explanatory variables. The indicator method (Miettinen 1985, 232) replaces each missing value by a zero and extends the regression model by the response indicator. The procedure is applied to each incomplete variable. The user analyzes the extended model instead of the original. In R the indicator method can be coded as imp &lt;- mice(airquality, method = &quot;mean&quot;, m = 1, maxit = 1, print = FALSE) airquality2 &lt;- cbind(complete(imp), r.Ozone = is.na(airquality[, &quot;Ozone&quot;])) fit &lt;- lm(Wind ~ Ozone + r.Ozone, data = airquality2) Observe that since the missing data are in Ozone we needed to reverse the direction of the regression model. The indicator method has been popular in public health and epidemiology. An advantage is that the indicator method retains the full dataset. Also, it allows for systematic differences between the observed and the unobserved data by inclusion of the response indicator, and could be more efficient. White and Thompson (2005) pointed out that the method can be useful to estimate the treatment effect in randomized trials when a baseline covariate is partially observed. If the missing data are restricted to the covariate, if the interest is solely restricted to estimation of the treatment effect, if compliance to the allocated treatment is perfect and if the model is linear without interactions, then using the indicator method for that covariate yields an unbiased estimate of the treatment effect. This is true even if the missingness depends on the covariate itself. Additional work can be found in Groenwold et al. (2012; Sullivan et al. 2018). It is not yet clear whether the coverage of the confidence interval around the treatment estimate will be satisfactory for multiple incomplete baseline covariates. The conditions under which the indicator method works may not be met in practice. For example, the method does not allow for missing data in the outcome, and generally fails in observational data. It has been shown that the method can yield severely biased regression estimates, even under MCAR and for low amounts of missing data (Vach and Blettner 1991; Greenland and Finkle 1995; Knol et al. 2010). The indicator method may have its uses in particular situations, but fails as a generic method to handle missing data. 1.3.8 Summary Table 1.1: Overview of assumptions made by ad-hoc methods. Unbiased Standard Error Mean Reg Weight Correlation Listwise MCAR MCAR MCAR Too large Pairwise MCAR MCAR MCAR Complicated Mean MCAR – – Too small Regression MAR MAR – Too small Stochastic MAR MAR MAR Too small LOCF – – – Too small Indicator – – – Too small Table 1.1 provides a summary of the methods discussed in this section. The table addresses two topics: whether the method yields the correct results on average (unbiasedness), and whether it produces the correct standard error. Unbiasedness is evaluated with respect to three types of estimates: the mean, the regression weight (with the incomplete variable as dependent) and the correlation. The table identifies the assumptions on the missing data mechanism each method must make in order to produce unbiased estimates. The first line of the table should be read as follows: Listwise deletion produces an unbiased estimate of the mean provided that the data are MCAR; Listwise deletion produces an estimate of the standard error that is too large. The interpretation of the other lines is similar. The “–” sign in some cells indicates that the method cannot produce unbiased estimates. Observe that both deletion methods require MCAR for all types. Regression imputation and stochastic regression imputation can yield unbiased estimates under MAR. In order to work, the model needs to be correctly specified. LOCF and the indicator method are incapable of providing consistent estimates, even under MCAR. Note that some special cases are not covered in Table 1.1. For example, listwise deletion is unbiased under two special MNAR scenarios (cf. Section ??). Listwise deletion produces standard errors that are correct for the subset of complete cases, but in general too large for the entire dataset. Calculation of standard errors under pairwise deletion is complicated. The standard errors after single imputation are too small since the standard calculations make no distinction between the observed data and the imputed data. Correction factors for some situations have been developed (Schafer and Schenker 2000), but a more convenient solution is multiple imputation. "],
["sec-nutshell.html", "1.4 Multiple imputation in a nutshell", " 1.4 Multiple imputation in a nutshell 1.4.1 Procedure Multiple imputation creates \\(m&gt;1\\) complete datasets. Each of these datasets is analyzed by standard analysis software. The \\(m\\) results are pooled into a final point estimate plus standard error by pooling rules (“Rubin’s rules”). Figure 1.6 illustrates the three main steps in multiple imputation: imputation, analysis and pooling. Figure 1.6: Scheme of main steps in multiple imputation. The analysis starts with observed, incomplete data. Multiple imputation creates several complete versions of the data by replacing the missing values by plausible data values. These plausible values are drawn from a distribution specifically modeled for each missing entry. Figure 1.6 portrays \\(m=3\\) imputed datasets. In practice, \\(m\\) is often taken larger (cf. Section ??). The number \\(m=3\\) is taken here just to make the point that the technique creates multiple versions of the imputed data. The three imputed datasets are identical for the observed data entries, but differ in the imputed values. The magnitude of these difference reflects our uncertainty about what value to impute. The second step is to estimate the parameters of interest from each imputed dataset. This is typically done by applying the analytic method that we would have used had the data been complete. The results will differ because their input data differ. It is important to realize that these differences are caused only because of the uncertainty about what value to impute. The last step is to pool the \\(m\\) parameter estimates into one estimate, and to estimate its variance. The variance combines the conventional sampling variance (within-imputation variance) and the extra variance caused by the missing data extra variance caused by the missing data (between-imputation variance). Under the appropriate conditions, the pooled estimates are unbiased and have the correct statistical properties. 1.4.2 Reasons to use multiple imputation Multiple imputation (Rubin 1987; Rubin 1996) solves the problem of “too small” standard errors in Table 1.1. Multiple imputation is unique in the sense that it provides a mechanism for dealing with the inherent uncertainty of the imputations themselves. Our level of confidence in a particular imputed value is expressed as the variation across the \\(m\\) completed datasets. For example, in a disability survey, suppose that the respondent answered the item whether he could walk, but did not provide an answer to the item whether he could get up from a chair. If the person can walk, then it is highly likely that the person will also be able to get up from the chair. Thus, for persons who can walk, we can draw a “yes” for missing “getting up from a chair” with a high probability, say 0.99, and use the drawn value as the imputed value. In the extreme, if we are really certain, we always impute the same value for that person. In general however, we are less confident about the true value. Suppose that, in a growth study, height is missing for a subject. If we only know that this person is a woman, this provides some information about likely values, but not so much. So the range of plausible values from which we draw is much larger here. The imputations for this woman will thus vary a lot over the different datasets. Multiple imputation is able to deal with both high-confidence and low-confidence situations equally well. Another reason to use multiple imputation is that it separates the solution of the missing data problem from the solution of the complete-data problem. The missing-data problem is solved first, the complete-data problem next. Though these phases are not completely independent, the answer to the scientifically interesting question is not obscured anymore by the missing data. The ability to separate the two phases simplifies statistical modeling, and hence contributes to a better insight into the phenomenon of scientific study. 1.4.3 Example of multiple imputation Continuing with the airquality dataset, it is straightforward to apply multiple imputation. The following code imputes the missing data twenty times, fits a linear regression model to predict Ozone in each of the imputed datasets, pools the twenty sets of estimated parameters, and calculates the Wald statistics for testing significance of the weights. imp &lt;- mice(airquality, seed = 1, m = 20, print = FALSE) fit &lt;- with(imp, lm(Ozone ~ Wind + Temp + Solar.R)) summary(pool(fit)) estimate std.error statistic df p.value (Intercept) -62.7055 21.1973 -2.96 106.3 0.003755025718 Wind -3.0839 0.6281 -4.91 91.7 0.000003024665 Temp 1.5988 0.2311 6.92 115.4 0.000000000271 Solar.R 0.0573 0.0217 2.64 112.8 0.009489765888 There is much more to say about each of these steps, but it shows that multiple imputation need not be a daunting task. Assuming we have set options(na.action = na.omit), fitting the same model to the complete cases can be done by fit &lt;- lm(Ozone ~ Wind + Temp + Solar.R, data = airquality) coef(summary(fit)) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -64.3421 23.0547 -2.79 0.00622663809 Wind -3.3336 0.6544 -5.09 0.00000151593 Temp 1.6521 0.2535 6.52 0.00000000242 Solar.R 0.0598 0.0232 2.58 0.01123663550 The solutions are nearly identical here, which is due to the fact that most missing values occur in the outcome variable. The standard errors of the multiple imputation solution are slightly smaller than in the complete-case analysis. Multiple imputation is often more efficient than complete-case analysis. Depending on the data and the model at hand, the differences can be dramatic. Figure 1.7: Multiple imputation of Ozone. Plotted are the imputed values from the first imputation. Figure 1.7 shows the distribution and scattergram for the observed and imputed data combined. The imputations are taken from the first completed dataset. The blue and red distributions are quite similar. Problems with the negative values as in Figure 1.4 are now gone since the imputation method used observed data as donors to fill the missing data. Section ?? describes the method in detail. Note that the red points respect the heteroscedastic nature of the relation between Ozone and Solar.R. All in all, the red points look as if they could have been measured if they had not been missing. The reader can easily recalculate the solution and inspect these plots for the other imputations. Figure 1.8: Multiple imputation of Ozone. Plotted are the observed values (in blue) and the multiply imputed values (in red). Figure 1.8 plots the completed Ozone data. The imputed data of all five imputations are plotted for the days with missing Ozone scores. In order to avoid clutter, the lines that connect the dots are not drawn for the imputed values. Note that the pattern of imputed values varies substantially over the days. At the beginning of the series, the values are low and the spread is small, in particular for the cold and windy days 25–27. The small spread for days 25–27 indicates that the model is quite sure of these values. High imputed values are found around the hot and sunny days 35–42, whereas the imputations during the moderate days 52–61 are consistently in the moderate range. Note how the available information helps determine sensible imputed values that respect the relations between wind, temperature, sunshine and ozone. One final point. The airquality data is a time series of 153 days. It is well known that the standard error of the ordinary least squares (OLS) estimate is inefficient (too large) if the residuals have positive serial correlation (Harvey 1981). The first three autocorrelations of the Ozone are indeed large: 0.48, 0.31 and 0.29. The residual autocorrelations are however small and within the confidence interval: 0.13, \\(-0.02\\) and 0.04. The inefficiency of OLS is thus negligible here. "],
["sec-goal.html", "1.5 Goal of the book", " 1.5 Goal of the book The main goal of this book is to add multiple imputation to the tool chest of practitioners. The text explains the ideas underlying multiple imputation, discusses when multiple imputation is useful, how to do it in practice and how to report the results of the steps taken. The computations are done with the help of the R package mice, written by Karin Groothuis-Oudshoorn and myself (Van Buuren and Groothuis-Oudshoorn 2011). The book thus also serves as an extended tutorial on the practical application of mice. Online materials that accompany the book can be found on www.multiple-imputation.com. My hope is that this hands-on approach will facilitate understanding of the key ideas in multiple imputation. "],
["sec-doesnotcover.html", "1.6 What the book does not cover", " 1.6 What the book does not cover The field of missing data research is vast. This book focuses on multiple imputation. The book does not attempt cover the enormous body of literature on alternative approaches to incomplete data. This section briefly reviews three of these approaches. 1.6.1 Prevention With the exception of P. E. McKnight et al. (2007 Chapter 4), books on missing data do not mention prevention. Yet, prevention of the missing data is the most direct attack on problems caused by the missing data. Prevention is fully in spirit with the quote of Orchard and Woodbury given on p. . There is a lot one could do to prevent missing data. The remainder of this section lists point-wise advice. Minimize the use of intrusive measures, like blood samples. Visit the subject at home. Use incentives to stimulate response, and try to match up the interviewer and respondent on age and ethnicity. Adapt the mode of the study (telephone, face to face, web questionnaire, and so on) to the study population. Use a multi-mode design for different groups in your study. Quickly follow-up for people that do not respond, and where possible try to retrieve any missing data from other sources. In experimental studies, try to minimize the treatment burden and intensity where possible. Prepare a well-thought-out flyer that explains the purpose and usefulness of your study. Try to organize data collection through an authority, e.g., the patient’s own doctor. Conduct a pilot study to detect and smooth out any problems. Economize on the number of variables collected. Only collect the information that is absolutely essential to your study. Use short forms of measurement instruments where possible. Eliminate vague or ambivalent questionnaire items. Use an attractive layout of the instruments. Refrain from using blocks of items that force the respondent to stay on a particular page for a long time. Use computerized adaptive testing where feasible. Do not allow other studies to piggy-back on your data collection efforts. Do not overdo it. Many Internet questionnaires are annoying because they force the respondent to answer. Do not force your respondent. The result will be an apparently complete dataset with mediocre data. Respect the wish of your respondent to skip items. The end result will be more informative. Use double coding in the data entry, and chase up any differences between the versions. Devise nonresponse forms in which you try to find out why people they did not respond, or why they dropped out. Last but not least, consult experts. Many academic centers have departments that specialize in research methodology. Sound expert advice may turn out to be extremely valuable for keeping your missing data rate under control. Most of this advice can be found in books on research methodology and data quality. Good books are Shadish, Cook, and Campbell (2001), De Leeuw, Hox, and Dillman (2008), Dillman, Smyth, and Melani Christian (2008) and Groves et al. (2009). 1.6.2 Weighting procedures Weighting is a method to reduce bias when the probability to be selected in the survey differs between respondents. In sample surveys, the responders are weighted by design weights, which are inversely proportional to their probability of being selected in the survey. If there are missing data, the complete cases are re-weighted according to design weights that are adjusted to counter any selection effects produced by nonresponse. The method is widely used in official statistics. Relevant pointers include Cochran (1977) and Särndal, Swensson, and Wretman (1992) and Bethlehem (2002). The method is relatively simple in that only one set of weights is needed for all incomplete variables. On the other hand, it discards data by listwise deletion, and it cannot handle partial response. Expressions for the variance of regression weights or correlations tend to be complex, or do not exist. The weights are estimated from the data, but are generally treated as fixed. The implications for this are unclear (Little and Rubin 2002, 53). There has been interest recently in improved weighting procedures that are “double robust” (Scharfstein, Rotnitzky, and Robins 1999; Bang and Robins 2005). This estimation method requires specification of three models: Model A is the scientifically interesting model, Model B is the response model for the outcome, and model C is the joint model for the predictors and the outcome. The dual robustness property states that: if either Model B or Model C is wrong (but not both), the estimates under Model A are still consistent. This seems like a useful property, but the issue is not free of controversy (Kang and Schafer 2007). 1.6.3 Likelihood-based approaches Likelihood-based approaches define a model for the observed data. Since the model is specialized to the observed values, there is no need to impute missing data or to discard incomplete cases. The inferences are based on the likelihood or posterior distribution under the posited model. The parameters are estimated by maximum likelihood, the EM algorithm, the sweep operator, Newton–Raphson, Bayesian simulation and variants thereof. These methods are smart ways to skip over the missing data, and are known as direct likelihood, full information maximum likelihood (FIML), and more recently, pairwise likelihood estimation. Likelihood-based methods are, in some sense, the “royal way” to treat missing data problems. The estimated parameters nicely summarize the available information under the assumed models for the complete data and the missing data. The model assumptions can be displayed and evaluated, and in many cases it is possible to estimate the standard error of the estimates. Multiple imputation extends likelihood-based methods by adding an extra step in which imputed data values are drawn. An advantage of this is that it is generally easier to calculate the standard errors for a wider range of parameters. Moreover, the imputed values created by multiple imputation can be inspected and analyzed, which helps us to gauge the effect of the model assumptions on the inferences. The likelihood-based approach receives an excellent treatment in the book by Little and Rubin (2002). A less technical account that should appeal to social scientists can be found in Enders (2010, chaps. 3–5). Molenberghs and Kenward (2007) provide a hands-on approach of likelihood-based methods geared toward clinical studies, including extensions to data that are MNAR. The pairwise likelihood method was introduced by Katsikatsou et al. (2012) and has been implemented in lavaan. "],
["sec-structure.html", "1.7 Structure of the book", " 1.7 Structure of the book This book consists of three main parts: basics, case studies and extensions. Chapter ?? reviews the history of multiple imputation and introduces the notation and theory. Chapter ?? provides an overview of imputation methods for univariate missing data. Chapter ?? distinguishes three approaches to attack the problem of multivariate missing data. Chapter ?? reviews issues pertaining to the analysis of the imputed datasets. Chapter ?? discusses practical issues for multivariate missing data. Chapter ?? discusses the problem how to impute for nested data so as to preserve the multilevel structure. Chapter ?? explores the use of multiple imputation to estimate individual causal effects. Chapters ??–?? contain case studies of the techniques described in the previous chapters. Chapter ?? deals with “problems with the columns,” while Chapter ?? addresses “problems with the rows”. Chapter ?? discusses studies on problems with both rows and columns. Chapter ?? concludes the main text with a discussion of limitations and pitfalls, reporting guidelines, alternative applications and future extensions. "],
["ex-ch1.html", "1.8 Exercises", " 1.8 Exercises Exercise 1.1 (Reporting practice) What are the reporting practices in your field? Take a random sample of articles that have appeared during the last 10 years in the leading journal in your field. Select only those that present quantitative analyses, and address the following topics: Did the authors report that there were missing data? If not, can you infer from the text that there must have been missing data? Did the authors discuss how they handled the missing data? Were the missing data properly addressed? Can you detect a trend over time in reporting practice? Would the editors of the journal be interested in your findings? Exercise 1.2 (Loss of information) Suppose that a dataset consists of 100 cases and 10 variables. Each variable contains 10% missing values. What is the largest possible subsample under listwise deletion? What is the smallest? If each variable is MCAR, how many cases will remain? Exercise 1.3 (Stochastic regression imputation) The correlation of the data in Figure 1.4 is equal to 0.33. This is relatively low compared to the other correlations reported in Section 1.3. This seems to contradict the statement that stochastic regression imputation does not bias the correlation. Could this low correlation be due to random variation? Rerun the code with a different seed value. What is the correlation now? Write a loop to apply apply stochastic regression imputation with the seed increasing from 1 to 1000. Calculate the regression weight and the correlation for each solution, and plot the histogram. What are the mean, minimum and maximum values of the correlation? Do your results indicate that stochastic regression imputation alters the correlation? Exercise 1.4 (Stochastic regression imputation (continued)) The largest correlation found in the previous exercise exceeds the value found in Section 1.3.4. This seems odd since the correlation of the imputed values under regression imputation is equal to 1, and hence the imputed data have a maximal contribution to the overall correlation. Can you explain why this could happen? Adapt the code from the previous exercise to test your explanation. Was your explanation satisfactory? If not, can you think of another reason, and test that? Hint: Find out what is special about the solutions with the largest correlations. Exercise 1.5 (Nonlinear model) The model fitted to the airquality data in Section 1.4.3 is a simple linear model. Inspection of the residuals reveals that there is a slight curvature in the average of the residuals. Start from the completed cases, and use plot(fit) to obtain diagnostic plots. Can you explain why the curvature shows up? Experiment with solutions, e.g., by transforming Ozone or by adding a quadratic term to the model. Can you make the curvature disappear? Does the amount of explained variance increase? Does the curvature also show up in the imputed data? If so, does the same solution work? Hint: You can assess the \\(j^\\mathrm{th}\\) fitted model by getfit(fit, j), where fit was created by with(imp,...). Advanced: Do you think your solution would necessitate drawing new imputations? "]
]
